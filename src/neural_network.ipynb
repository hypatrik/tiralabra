{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import NeuralNetwork\n",
    "import pickle\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# useiden eri mnist datasettien jälkeen päädyin tähän pikkelöityyn\n",
    "# https://www.kaggle.com/datasets/pablotab/mnistpklgz\n",
    "with gzip.open('../data/mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "print(len(train_set[0]))\n",
    "print(len(train_set[0][0]))\n",
    "type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning with 50000 elements\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n",
      "batch 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m NeuralNetwork([\u001b[39mlen\u001b[39m(train_set[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]), \u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_set[\u001b[39m0\u001b[39;49m], train_set[\u001b[39m1\u001b[39;49m], \u001b[39m10\u001b[39;49m, \u001b[39m30\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/studies/tiralabra/tiralabra/src/model.py:59\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X, y, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m split_every(batch_size, training_data):\n\u001b[1;32m     58\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbatch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(batch)))\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(batch, learning_rate)\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m done\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n",
      "File \u001b[0;32m~/studies/tiralabra/tiralabra/src/model.py:69\u001b[0m, in \u001b[0;36mNeuralNetwork.update\u001b[0;34m(self, batch, learning_rate)\u001b[0m\n\u001b[1;32m     66\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch)\n\u001b[1;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m batch:\n\u001b[0;32m---> 69\u001b[0m     delta_weights, delta_biases \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackpropagation(x, y)\n\u001b[1;32m     70\u001b[0m     weight_gradients \u001b[39m=\u001b[39m [\n\u001b[1;32m     71\u001b[0m         w_gradient \u001b[39m+\u001b[39m delta_w\n\u001b[1;32m     72\u001b[0m         \u001b[39mfor\u001b[39;00m w_gradient, delta_w \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(weight_gradients, delta_weights)\n\u001b[1;32m     73\u001b[0m     ]\n\u001b[1;32m     74\u001b[0m     bias_gradients \u001b[39m=\u001b[39m [\n\u001b[1;32m     75\u001b[0m         b_gradient \u001b[39m+\u001b[39m delta_nb\n\u001b[1;32m     76\u001b[0m         \u001b[39mfor\u001b[39;00m b_gradient, delta_nb \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(bias_gradients, delta_biases)\n\u001b[1;32m     77\u001b[0m     ]\n",
      "File \u001b[0;32m~/studies/tiralabra/tiralabra/src/model.py:107\u001b[0m, in \u001b[0;36mNeuralNetwork.backpropagation\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    105\u001b[0m z_vectors \u001b[39m=\u001b[39m []\n\u001b[1;32m    106\u001b[0m \u001b[39mfor\u001b[39;00m b, w \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights):\n\u001b[0;32m--> 107\u001b[0m     z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(w, a_vectors[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39m+\u001b[39m b\n\u001b[1;32m    108\u001b[0m     z_vectors\u001b[39m.\u001b[39mappend(z)\n\u001b[1;32m    109\u001b[0m     a_vectors\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function(z))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork([len(train_set[0][0]), 5, 10])\n",
    "model.fit(train_set[0], train_set[1], 10, 30, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
